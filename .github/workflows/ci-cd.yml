name: CI/CD Pipeline

on:
  push:
    branches: [ main, master, develop ]
  pull_request:
    branches: [ main, master ]

env:
  IMAGE_NAME: zoneapi
  HELM_VERSION: 3.12.0

jobs:
  # Build and Test Job
  build-and-test:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Setup .NET
      uses: actions/setup-dotnet@v4
      with:
        dotnet-version: 7.0.x
    
    - name: Restore dependencies
      run: dotnet restore ZoneAPI/ZoneAPI.csproj
    
    - name: Build application
      run: dotnet build ZoneAPI/ZoneAPI.csproj --no-restore --configuration Release
    
    - name: Run tests
      run: dotnet test ZoneAPI/ZoneAPI.csproj --no-build --configuration Release --verbosity normal
    
    # Upload build artifacts
    - name: Upload build artifacts
      uses: actions/upload-artifact@v4
      with:
        name: build-artifacts
        path: ZoneAPI/bin/Release/
        retention-days: 1

  # Infrastructure Deployment Job
  deploy-infrastructure:
    runs-on: ubuntu-latest
    needs: build-and-test
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
    
    outputs:
      aks-cluster-name: ${{ steps.terraform-output.outputs.aks-cluster-name }}
      resource-group: ${{ steps.terraform-output.outputs.resource-group }}
      postgres-host: ${{ steps.terraform-output.outputs.postgres-host }}
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Azure Login
      uses: azure/login@v1
      with:
        creds: ${{ secrets.AZURE_CREDENTIALS }}
    
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: 1.5.0
        terraform_wrapper: false
    
    - name: Terraform Format Check
      run: terraform fmt -check
      working-directory: ./terraform
    
    - name: Setup Terraform Backend (if needed)
      run: |
        # Check if backend storage account exists, create if not
        if ! az storage account show --name tfstatezoneapi --resource-group rg-terraform-state >/dev/null 2>&1; then
          echo "Setting up Terraform backend..."
          ./scripts/setup-terraform-backend.sh
        else
          echo "Terraform backend already exists"
        fi
    
    - name: Terraform Init
      run: terraform init
      working-directory: ./terraform
      env:
        ARM_CLIENT_ID: ${{ secrets.ARM_CLIENT_ID }}
        ARM_CLIENT_SECRET: ${{ secrets.ARM_CLIENT_SECRET }}
        ARM_SUBSCRIPTION_ID: ${{ secrets.ARM_SUBSCRIPTION_ID }}
        ARM_TENANT_ID: ${{ secrets.ARM_TENANT_ID }}
    
    - name: Terraform Plan
      run: terraform plan -out=tfplan
      working-directory: ./terraform
      env:
        ARM_CLIENT_ID: ${{ secrets.ARM_CLIENT_ID }}
        ARM_CLIENT_SECRET: ${{ secrets.ARM_CLIENT_SECRET }}
        ARM_SUBSCRIPTION_ID: ${{ secrets.ARM_SUBSCRIPTION_ID }}
        ARM_TENANT_ID: ${{ secrets.ARM_TENANT_ID }}
        TF_VAR_postgres_admin_password: ${{ secrets.POSTGRES_ADMIN_PASSWORD }}
    
    - name: Terraform Apply
      run: terraform apply -auto-approve tfplan
      working-directory: ./terraform
      env:
        ARM_CLIENT_ID: ${{ secrets.ARM_CLIENT_ID }}
        ARM_CLIENT_SECRET: ${{ secrets.ARM_CLIENT_SECRET }}
        ARM_SUBSCRIPTION_ID: ${{ secrets.ARM_SUBSCRIPTION_ID }}
        ARM_TENANT_ID: ${{ secrets.ARM_TENANT_ID }}
        TF_VAR_postgres_admin_password: ${{ secrets.POSTGRES_ADMIN_PASSWORD }}
    
    - name: Get Terraform Outputs
      id: terraform-output
      run: |
        echo "aks-cluster-name=$(terraform output -raw aks_cluster_name)" >> $GITHUB_OUTPUT
        echo "resource-group=$(terraform output -raw resource_group_name)" >> $GITHUB_OUTPUT
        echo "postgres-host=$(terraform output -raw postgres_server_fqdn)" >> $GITHUB_OUTPUT
      working-directory: ./terraform
      env:
        ARM_CLIENT_ID: ${{ secrets.ARM_CLIENT_ID }}
        ARM_CLIENT_SECRET: ${{ secrets.ARM_CLIENT_SECRET }}
        ARM_SUBSCRIPTION_ID: ${{ secrets.ARM_SUBSCRIPTION_ID }}
        ARM_TENANT_ID: ${{ secrets.ARM_TENANT_ID }}

  # Docker Build and Push Job
  docker-build-push:
    runs-on: ubuntu-latest
    needs: deploy-infrastructure
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
    
    outputs:
      image-tag: ${{ steps.image-tag.outputs.tag }}
      image-digest: ${{ steps.build.outputs.digest }}
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Generate image tag
      id: image-tag
      run: |
        if [ "${{ github.ref }}" == "refs/heads/main" ] || [ "${{ github.ref }}" == "refs/heads/master" ]; then
          echo "tag=latest" >> $GITHUB_OUTPUT
        else
          echo "tag=${{ github.sha }}" >> $GITHUB_OUTPUT
        fi
    
    - name: Azure Login
      uses: azure/login@v1
      with:
        creds: ${{ secrets.AZURE_CREDENTIALS }}
    
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: 1.5.0
        terraform_wrapper: false
    
    - name: Get ACR login server from Terraform
      id: acr-info
      run: |
        # Setup Terraform backend (since this is a separate job)
        if ! az storage account show --name tfstatezoneapi --resource-group rg-terraform-state >/dev/null 2>&1; then
          echo "Setting up Terraform backend..."
          ./scripts/setup-terraform-backend.sh
        else
          echo "Terraform backend already exists"
        fi
        
        cd terraform
        # Initialize Terraform with backend
        terraform init
        ACR_LOGIN_SERVER=$(terraform output -raw acr_login_server)
        ACR_USERNAME=$(terraform output -raw acr_admin_username)
        ACR_PASSWORD=$(terraform output -raw acr_admin_password)
        echo "::add-mask::$ACR_PASSWORD"
        echo "login-server=$ACR_LOGIN_SERVER" >> $GITHUB_OUTPUT
        echo "username=$ACR_USERNAME" >> $GITHUB_OUTPUT
        echo "password=$ACR_PASSWORD" >> $GITHUB_OUTPUT
      env:
        ARM_CLIENT_ID: ${{ secrets.ARM_CLIENT_ID }}
        ARM_CLIENT_SECRET: ${{ secrets.ARM_CLIENT_SECRET }}
        ARM_SUBSCRIPTION_ID: ${{ secrets.ARM_SUBSCRIPTION_ID }}
        ARM_TENANT_ID: ${{ secrets.ARM_TENANT_ID }}
    
    - name: Log in to Azure Container Registry
      uses: azure/docker-login@v1
      with:
        login-server: ${{ steps.acr-info.outputs.login-server }}
        username: ${{ steps.acr-info.outputs.username }}
        password: ${{ steps.acr-info.outputs.password }}
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Build and push Docker image
      id: build
      uses: docker/build-push-action@v5
      with:
        context: .
        push: true
        tags: ${{ steps.acr-info.outputs.login-server }}/${{ env.IMAGE_NAME }}:${{ steps.image-tag.outputs.tag }}
        labels: |
          org.opencontainers.image.title=${{ env.IMAGE_NAME }}
          org.opencontainers.image.description=ZoneAPI - Healthcare Appointment Management System
          org.opencontainers.image.source=${{ github.repository }}
          org.opencontainers.image.revision=${{ github.sha }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

# Migration Job (Industry Best Practice - Separate from Deployment)
  run-migration:
    runs-on: ubuntu-latest
    needs: [deploy-infrastructure, docker-build-push]
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Azure Login
      uses: azure/login@v1
      with:
        creds: ${{ secrets.AZURE_CREDENTIALS }}
    
    - name: Get AKS credentials
      run: |
        az aks get-credentials \
          --resource-group ${{ needs.deploy-infrastructure.outputs.resource-group }} \
          --name ${{ needs.deploy-infrastructure.outputs.aks-cluster-name }} \
          --overwrite-existing

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: 1.5.0
        terraform_wrapper: false
    
    - name: Get Infrastructure Details
      id: infra
      run: |
        # Setup Terraform backend
        if ! az storage account show --name tfstatezoneapi --resource-group rg-terraform-state >/dev/null 2>&1; then
          echo "Setting up Terraform backend..."
          ./scripts/setup-terraform-backend.sh
        fi
        
        cd terraform
        terraform init
        
        echo "=== Terraform Outputs Debug ==="
        terraform output || echo "Failed to get terraform outputs"
        
        ACR_LOGIN_SERVER=$(terraform output -raw acr_login_server 2>/dev/null || echo "")
        POSTGRES_HOST=$(terraform output -raw postgres_server_fqdn 2>/dev/null || echo "")
        
        echo "Retrieved values:"
        echo "ACR_LOGIN_SERVER: ${ACR_LOGIN_SERVER:-[EMPTY]}"
        echo "POSTGRES_HOST: ${POSTGRES_HOST:-[EMPTY]}"
        
        if [ -z "$ACR_LOGIN_SERVER" ] || [ -z "$POSTGRES_HOST" ]; then
          echo "‚ùå Failed to retrieve required Terraform outputs"
          echo "Available outputs:"
          terraform output -json | jq -r 'keys[]' || echo "No outputs available"
          exit 1
        fi
        
        echo "acr-login-server=$ACR_LOGIN_SERVER" >> $GITHUB_OUTPUT
        echo "postgres-host=$POSTGRES_HOST" >> $GITHUB_OUTPUT
      env:
        ARM_CLIENT_ID: ${{ secrets.ARM_CLIENT_ID }}
        ARM_CLIENT_SECRET: ${{ secrets.ARM_CLIENT_SECRET }}
        ARM_SUBSCRIPTION_ID: ${{ secrets.ARM_SUBSCRIPTION_ID }}
        ARM_TENANT_ID: ${{ secrets.ARM_TENANT_ID }}
    
    - name: üßπ Clean Up Old Migration Jobs (Start with Clean Environment)
      timeout-minutes: 3
      run: |
        echo "=== üßπ CLEANING UP OLD MIGRATION JOBS ==="
        echo "Removing all previous migration jobs and pods for a clean start..."
        
        # Make cleanup script executable
        chmod +x ./scripts/cleanup-migration-jobs.sh
        
        # Run cleanup with force option to ensure everything is removed
        ./scripts/cleanup-migration-jobs.sh zoneapi true
        
        echo "‚úÖ Environment cleaned successfully!"

    - name: üîß Validate Environment Variables
      timeout-minutes: 1
      run: |
        echo "=== üîß VALIDATING ENVIRONMENT VARIABLES ==="
        
        # Set environment variables for testing
        export ACR_LOGIN_SERVER="${{ steps.infra.outputs.acr-login-server }}"
        export DATABASE_HOST="${{ steps.infra.outputs.postgres-host }}"
        export DB_PASSWORD="${{ secrets.POSTGRES_ADMIN_PASSWORD }}"
        export IMAGE_TAG="${{ needs.docker-build-push.outputs.image-tag }}"
        export NAMESPACE="zoneapi"
        
        # Validate environment variables
        echo "Required Environment Variables:"
        echo "ACR_LOGIN_SERVER: ${ACR_LOGIN_SERVER:-[NOT SET]}"
        echo "DATABASE_HOST: ${DATABASE_HOST:-[NOT SET]}"
        echo "DB_PASSWORD: ${DB_PASSWORD:+[PROVIDED]}"
        echo "IMAGE_TAG: ${IMAGE_TAG:-[NOT SET]}"
        echo "NAMESPACE: ${NAMESPACE:-[NOT SET]}"
        
        echo ""
        echo "Constructed Image Path:"
        if [ -n "$ACR_LOGIN_SERVER" ] && [ -n "$IMAGE_TAG" ]; then
            echo "Full Image: ${ACR_LOGIN_SERVER}/zoneapi:${IMAGE_TAG}"
        else
            echo "‚ùå Cannot construct image path - missing ACR_LOGIN_SERVER or IMAGE_TAG"
            exit 1
        fi
        
        echo ""
        echo "Database Connection String:"
        if [ -n "$DATABASE_HOST" ] && [ -n "$DB_PASSWORD" ]; then
            echo "Connection: Host=${DATABASE_HOST};Port=5432;Database=zone;Username=postgres;Password=[HIDDEN];CommandTimeout=300;Timeout=60;"
        else
            echo "‚ùå Cannot construct connection string - missing DATABASE_HOST or DB_PASSWORD"
            exit 1
        fi
        
        echo "‚úÖ Environment variables validated!"

    - name: üîç Pre-Migration Database Connection Tests
      timeout-minutes: 3
      run: |
        echo "=== üîç PRE-MIGRATION DATABASE CONNECTION TESTS ==="
        echo "Testing database connectivity before starting migration..."
        
        export DB_HOST="${{ steps.infra.outputs.postgres-host }}"
        export DB_PASSWORD="${{ secrets.POSTGRES_ADMIN_PASSWORD }}"
        
        echo "Database Host: $DB_HOST"
        echo "Testing from GitHub Actions runner..."
        
        # Install PostgreSQL client for testing
        sudo apt-get update
        sudo apt-get install -y postgresql-client
        
        # Run comprehensive database connection test
        chmod +x ./scripts/test-db-connection.sh
        ./scripts/test-db-connection.sh "$DB_HOST" "$DB_PASSWORD"
        
        echo "‚úÖ Database connection pre-checks completed successfully!"

    - name: üß™ Test Database Connection from Kubernetes
      timeout-minutes: 3
      run: |
        echo "=== üß™ TESTING DATABASE CONNECTION FROM KUBERNETES ==="
        
        # Create a test pod to verify connectivity from within the cluster
        kubectl run db-connection-test \
          --image=postgres:15-alpine \
          --rm -i --restart=Never \
          --namespace=zoneapi \
          --overrides='{
            "spec": {
              "containers": [{
                "name": "db-test",
                "image": "postgres:15-alpine",
                "env": [{
                  "name": "PGPASSWORD",
                  "valueFrom": {
                    "secretKeyRef": {
                      "name": "zoneapi-db-secret",
                      "key": "password"
                    }
                  }
                }],
                "command": ["psql"],
                "args": [
                  "-h", "${{ steps.infra.outputs.postgres-host }}",
                  "-U", "postgres",
                  "-d", "zone",
                  "-c", "SELECT version(); SELECT current_database(); SELECT current_user;"
                ]
              }]
            }
          }' \
          --timeout=120s
        
        echo "‚úÖ Kubernetes-to-Database connection test completed!"

    - name: üìä Pre-Migration Database State Check
      timeout-minutes: 3
      run: |
        echo "=== üìä PRE-MIGRATION DATABASE STATE CHECK ==="
        
        kubectl run db-state-check \
          --image=postgres:15-alpine \
          --rm -i --restart=Never \
          --namespace=zoneapi \
          --overrides='{
            "spec": {
              "containers": [{
                "name": "db-state",
                "image": "postgres:15-alpine",
                "env": [{
                  "name": "PGPASSWORD",
                  "valueFrom": {
                    "secretKeyRef": {
                      "name": "zoneapi-db-secret",
                      "key": "password"
                    }
                  }
                }],
                "command": ["psql"],
                "args": [
                  "-h", "${{ steps.infra.outputs.postgres-host }}",
                  "-U", "postgres",
                  "-d", "zone",
                  "-c", "\\dt; SELECT table_name FROM information_schema.tables WHERE table_schema = '\''public'\''; SELECT COUNT(*) as migration_history FROM __EFMigrationsHistory;"
                ]
              }]
            }
          }' \
          --timeout=120s || echo "‚ö†Ô∏è  Migration history table may not exist yet (first run)"
        
        echo "‚úÖ Database state check completed!"

    - name: Run Database Migration (efbundle Approach) with Enhanced Monitoring
      timeout-minutes: 3
      run: |
        echo "=== üöÄ RUNNING DATABASE MIGRATION (EFBUNDLE APPROACH) ==="
        
        # Set environment variables for migration script
        export ACR_LOGIN_SERVER="${{ steps.infra.outputs.acr-login-server }}"
        export DATABASE_HOST="${{ steps.infra.outputs.postgres-host }}"
        export DB_PASSWORD="${{ secrets.POSTGRES_ADMIN_PASSWORD }}"
        export IMAGE_TAG="${{ needs.docker-build-push.outputs.image-tag }}"
        export NAMESPACE="zoneapi"
        export TIMEOUT="900"  # Increased timeout for better monitoring
        
        # Debug: Check if environment variables are set
        echo "=== Environment Variable Debug ==="
        echo "ACR_LOGIN_SERVER from infra step: ${ACR_LOGIN_SERVER:-[EMPTY]}"
        echo "DATABASE_HOST from infra step: ${DATABASE_HOST:-[EMPTY]}"
        echo "IMAGE_TAG from docker build: ${IMAGE_TAG:-[EMPTY]}"
        
        # Fallback: If ACR_LOGIN_SERVER is empty, try to get it from Terraform directly
        if [ -z "$ACR_LOGIN_SERVER" ]; then
          echo "‚ö†Ô∏è ACR_LOGIN_SERVER is empty, attempting to retrieve from Terraform..."
          cd terraform && terraform init
          ACR_LOGIN_SERVER=$(terraform output -raw acr_login_server 2>/dev/null || echo "")
          echo "ACR_LOGIN_SERVER from Terraform: ${ACR_LOGIN_SERVER:-[STILL EMPTY]}"
          cd ..
        fi
        
        # Fallback: If DATABASE_HOST is empty, try to get it from Terraform directly  
        if [ -z "$DATABASE_HOST" ]; then
          echo "‚ö†Ô∏è DATABASE_HOST is empty, attempting to retrieve from Terraform..."
          cd terraform && terraform init
          DATABASE_HOST=$(terraform output -raw postgres_server_fqdn 2>/dev/null || echo "")
          echo "DATABASE_HOST from Terraform: ${DATABASE_HOST:-[STILL EMPTY]}"
          cd ..
        fi
        
        # Final validation
        if [ -z "$ACR_LOGIN_SERVER" ] || [ -z "$DATABASE_HOST" ] || [ -z "$DB_PASSWORD" ] || [ -z "$IMAGE_TAG" ]; then
          echo "‚ùå Required environment variables are missing:"
          echo "ACR_LOGIN_SERVER: ${ACR_LOGIN_SERVER:-[MISSING]}"
          echo "DATABASE_HOST: ${DATABASE_HOST:-[MISSING]}"
          echo "DB_PASSWORD: ${DB_PASSWORD:+[PROVIDED]}"
          echo "IMAGE_TAG: ${IMAGE_TAG:-[MISSING]}"
          exit 1
        fi
        
        echo "Migration Configuration:"
        echo "- ACR: $ACR_LOGIN_SERVER"
        echo "- Database Host: $DATABASE_HOST"  
        echo "- Image Tag: $IMAGE_TAG"
        echo "- Namespace: $NAMESPACE"
        echo "- Timeout: $TIMEOUT seconds"
        
        # Setup Helm
        curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
        
        # Make script executable
        chmod +x ./scripts/run-migration.sh
        
        # Start migration monitoring in background
        ./scripts/monitor-pipeline.sh &
        MONITOR_PID=$!
        
        # Run migration using efbundle approach
        echo "üèÉ‚Äç‚ôÇÔ∏è Starting migration process..."
        if ./scripts/run-migration.sh; then
          echo "‚úÖ Migration script completed successfully!"
        else
          echo "‚ùå Migration script failed!"
          exit 1
        fi
        
        # Stop monitoring
        kill $MONITOR_PID 2>/dev/null || true
    
    - name: üîç Detailed Migration Job Analysis
      if: always()
      run: |
        echo "=== üîç DETAILED MIGRATION JOB ANALYSIS ==="
        
        echo "=== Migration Jobs ==="
        kubectl get jobs -n zoneapi -l app.kubernetes.io/component=migration -o wide
        
        echo "=== Migration Pods ==="
        kubectl get pods -n zoneapi -l app.kubernetes.io/component=migration -o wide
        
        echo "=== Recent Migration Events ==="
        kubectl get events --namespace=zoneapi --field-selector involvedObject.kind=Job --sort-by='.lastTimestamp' | tail -20
        
        # Get the latest migration job
        latest_job=$(kubectl get jobs -n zoneapi -l app.kubernetes.io/component=migration --sort-by=.metadata.creationTimestamp -o jsonpath='{.items[-1].metadata.name}' 2>/dev/null || echo "")
        
        if [ -n "$latest_job" ]; then
          echo "=== Latest Migration Job Details: $latest_job ==="
          kubectl describe job "$latest_job" -n zoneapi
          
          echo "=== Migration Job Logs ==="
          kubectl logs -l job-name="$latest_job" -n zoneapi --tail=200 || echo "No logs available"
          
          # Check job status
          job_status=$(kubectl get job "$latest_job" -n zoneapi -o jsonpath='{.status.conditions[0].type}' 2>/dev/null || echo "Unknown")
          echo "Migration Job Status: $job_status"
          
          if [ "$job_status" = "Complete" ]; then
            echo "‚úÖ Migration completed successfully!"
          elif [ "$job_status" = "Failed" ]; then
            echo "‚ùå Migration failed!"
            
            # Get failed pod logs for debugging
            failed_pods=$(kubectl get pods -n zoneapi -l job-name="$latest_job" --field-selector=status.phase=Failed -o jsonpath='{.items[*].metadata.name}' 2>/dev/null || echo "")
            for pod in $failed_pods; do
              echo "=== Failed Pod Logs: $pod ==="
              kubectl logs "$pod" -n zoneapi || echo "Cannot retrieve logs for $pod"
            done
          fi
        else
          echo "‚ö†Ô∏è  No migration job found"
        fi

    - name: üìä Post-Migration Database Verification
      timeout-minutes: 3
      run: |
        echo "=== üìä POST-MIGRATION DATABASE VERIFICATION ==="
        
        kubectl run post-migration-check \
          --image=postgres:15-alpine \
          --rm -i --restart=Never \
          --namespace=zoneapi \
          --overrides='{
            "spec": {
              "containers": [{
                "name": "post-migration",
                "image": "postgres:15-alpine",
                "env": [{
                  "name": "PGPASSWORD",
                  "valueFrom": {
                    "secretKeyRef": {
                      "name": "zoneapi-db-secret",
                      "key": "password"
                    }
                  }
                }],
                "command": ["psql"],
                "args": [
                  "-h", "${{ steps.infra.outputs.postgres-host }}",
                  "-U", "postgres",
                  "-d", "zone",
                  "-c", "\\dt; SELECT COUNT(*) as total_migrations FROM __EFMigrationsHistory; SELECT migration_id, product_version FROM __EFMigrationsHistory ORDER BY migration_id;"
                ]
              }]
            }
          }' \
          --timeout=120s
        
        echo "‚úÖ Post-migration database verification completed!"

    - name: üõ†Ô∏è Comprehensive Migration Troubleshooting
      if: failure()
      run: |
        echo "=== üõ†Ô∏è COMPREHENSIVE MIGRATION TROUBLESHOOTING ==="
        
        # Run the comprehensive debug script
        chmod +x ./scripts/debug-migration-status.sh
        ./scripts/debug-migration-status.sh zoneapi || echo "Debug script completed with issues"
        
        echo ""
        echo "=== üîç ADDITIONAL CLUSTER DIAGNOSTICS ==="
        
        echo "=== Resource Usage ==="
        kubectl top nodes 2>/dev/null || echo "Metrics server not available"
        kubectl top pods -n zoneapi 2>/dev/null || echo "Pod metrics not available"
        
        echo "=== Network Diagnostics ==="
        kubectl get networkpolicies -n zoneapi 2>/dev/null || echo "No network policies found"
        kubectl get ingress -n zoneapi -o wide 2>/dev/null || echo "No ingress found"
        
        echo "=== Storage Diagnostics ==="
        kubectl get pv,pvc -n zoneapi 2>/dev/null || echo "No persistent volumes found"
        kubectl describe quota -n zoneapi 2>/dev/null || echo "No resource quotas found"
        
        echo "=== Extended Event History ==="
        kubectl get events -n zoneapi --sort-by='.lastTimestamp' | tail -50
        
        # Run additional health checks
        chmod +x ./scripts/debug-health-checks.sh
        ./scripts/debug-health-checks.sh || echo "Health check script completed with issues"
    
    - name: Verify Migration Success
      if: always()
      run: |
        echo "=== FINAL MIGRATION STATUS SUMMARY ==="
        
        # Check if any migration jobs completed successfully
        completed_jobs=$(kubectl get jobs -n zoneapi -l app.kubernetes.io/component=migration -o jsonpath='{.items[?(@.status.conditions[0].type=="Complete")].metadata.name}' 2>/dev/null || echo "")
        failed_jobs=$(kubectl get jobs -n zoneapi -l app.kubernetes.io/component=migration -o jsonpath='{.items[?(@.status.conditions[0].type=="Failed")].metadata.name}' 2>/dev/null || echo "")
        
        if [ -n "$completed_jobs" ]; then
          echo "‚úÖ Successfully completed migration jobs: $completed_jobs"
        fi
        
        if [ -n "$failed_jobs" ]; then
          echo "‚ùå Failed migration jobs: $failed_jobs"
          exit 1
        fi
        
        if [ -z "$completed_jobs" ] && [ -z "$failed_jobs" ]; then
          echo "‚ö†Ô∏è  No migration jobs found or jobs still running"
          exit 1
        fi

  # Application Deployment Job (Completely Separate)
  deploy-application:
    runs-on: ubuntu-latest
    needs: [deploy-infrastructure, docker-build-push, run-migration]
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Azure Login
      uses: azure/login@v1
      with:
        creds: ${{ secrets.AZURE_CREDENTIALS }}
    
    - name: Setup Helm
      uses: azure/setup-helm@v3
      with:
        version: ${{ env.HELM_VERSION }}
    
    - name: Get AKS credentials
      run: |
        az aks get-credentials \
          --resource-group ${{ needs.deploy-infrastructure.outputs.resource-group }} \
          --name ${{ needs.deploy-infrastructure.outputs.aks-cluster-name }} \
          --overwrite-existing

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: 1.5.0
        terraform_wrapper: false

    - name: Get ACR login server from Terraform
      id: acr-info
      run: |
        # Setup Terraform backend
        if ! az storage account show --name tfstatezoneapi --resource-group rg-terraform-state >/dev/null 2>&1; then
          echo "Setting up Terraform backend..."
          ./scripts/setup-terraform-backend.sh
        fi
        
        cd terraform
        terraform init
        ACR_LOGIN_SERVER=$(terraform output -raw acr_login_server)
        echo "login-server=$ACR_LOGIN_SERVER" >> $GITHUB_OUTPUT
      env:
        ARM_CLIENT_ID: ${{ secrets.ARM_CLIENT_ID }}
        ARM_CLIENT_SECRET: ${{ secrets.ARM_CLIENT_SECRET }}
        ARM_SUBSCRIPTION_ID: ${{ secrets.ARM_SUBSCRIPTION_ID }}
        ARM_TENANT_ID: ${{ secrets.ARM_TENANT_ID }}
    
    - name: Deploy Application (Post-Migration)
      timeout-minutes: 3
      run: |
        echo "=== DEPLOYING APPLICATION (POST-MIGRATION) ==="
        echo "Image: ${{ steps.acr-info.outputs.login-server }}/${{ env.IMAGE_NAME }}:${{ needs.docker-build-push.outputs.image-tag }}"
        echo "Database: ${{ needs.deploy-infrastructure.outputs.postgres-host }}"
        
        # Deploy application with proper health checks enabled
        helm upgrade --install zoneapi ./charts/zoneapi \
          --namespace zoneapi \
          --create-namespace \
          --set migration.enabled=false \
          --set image.repository=${{ steps.acr-info.outputs.login-server }}/${{ env.IMAGE_NAME }} \
          --set image.tag=${{ needs.docker-build-push.outputs.image-tag }} \
          --set imagePullSecrets[0].name=acr-secret \
          --set database.host=${{ needs.deploy-infrastructure.outputs.postgres-host }} \
          --set database.password=${{ secrets.POSTGRES_ADMIN_PASSWORD }} \
          --set livenessProbe.enabled=true \
          --set readinessProbe.enabled=true \
          --set replicaCount=1 \
          --force \
          --wait --timeout=8m \
          --debug
    
    - name: Verify Deployment
      if: always()
      run: |
        echo "=== DEPLOYMENT VERIFICATION ==="
        
        echo "=== Pods Status ==="
        kubectl get pods -n zoneapi -o wide
        
        echo "=== Services ==="
        kubectl get services -n zoneapi -o wide
        
        echo "=== Recent Events ==="
        kubectl get events -n zoneapi --sort-by='.lastTimestamp' | tail -20
        
        echo "=== Pod Logs (if any issues) ==="
        kubectl logs -l app.kubernetes.io/name=zoneapi -n zoneapi --tail=50 || echo "No pod logs available"
    
    - name: Health Check Test
      run: |
        echo "=== HEALTH CHECK TEST ==="
        
        # Get pod name
        pod_name=$(kubectl get pods -n zoneapi -l app.kubernetes.io/name=zoneapi -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "")
        
        if [ -n "$pod_name" ]; then
          echo "Testing pod: $pod_name"
          
          # Wait for pod to be ready
          kubectl wait --for=condition=ready pod/$pod_name -n zoneapi --timeout=120s
          
          # Test health endpoint
          echo "Testing health endpoint..."
          kubectl exec -n zoneapi $pod_name -- curl -f http://localhost:8080/health
          
          echo "‚úÖ Health check passed!"
        else
          echo "‚ö†Ô∏è  No pods found to test"
        fi 